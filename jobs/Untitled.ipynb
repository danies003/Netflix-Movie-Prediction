{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #!/usr/bin/env python\n",
    "        # coding: utf-8\n",
    "\n",
    "        # # DOE\n",
    "\n",
    "        # In[2]:\n",
    "        from django.core.management.base import BaseCommand\n",
    "        from urllib.request import urlopen\n",
    "        from bs4 import BeautifulSoup\n",
    "        import json\n",
    "\n",
    "        import urllib.request as req\n",
    "        import pandas as pd\n",
    "        import bs4\n",
    "        import os\n",
    "        import psycopg2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        url=\"https://www.nsf.gov/news/\"\n",
    "        request=req.Request(url, headers={\"user-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36\"})\n",
    "        with req.urlopen(request) as response:\n",
    "            data=response.read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "        root=bs4.BeautifulSoup(data, \"html.parser\")\n",
    "        links=root.find('div',class_=\"col-md-12 l-add__border\")\n",
    "        list1={'title':[],'href':[],'time':[]}\n",
    "        for a in links.find_all(\"div\", {\"class\":\"media l-media\"}):\n",
    "            for b in a.find_all(\"div\", {\"class\":\"media-body\"}):\n",
    "\n",
    "                for c in b.find_all(\"span\", {\"class\":\"l-media__date\" }):\n",
    "                        list1['time'].append(c.get_text())\n",
    "\n",
    "                for d in b.find_all(\"a\"):\n",
    "                        list1['title'].append(d.get_text())\n",
    "\n",
    "\n",
    "                        if \"https://\" in d['href']:\n",
    "\n",
    "                            list1['href'].append(d['href'])\n",
    "\n",
    "                        else:\n",
    "                            list1['href'].append(\"https://www.nsf.gov\"+d['href'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        NSF = pd.DataFrame(list1, columns=['time', 'title', 'href'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # FAA \n",
    "\n",
    "        # In[4]:\n",
    "\n",
    "\n",
    "\n",
    "        url=\"https://www.faa.gov/news/\"\n",
    "        request=req.Request(url, headers={\"user-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36\"})\n",
    "        with req.urlopen(request) as response:\n",
    "            data=response.read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "        root=bs4.BeautifulSoup(data, \"html.parser\")\n",
    "        links=root.find('article',class_=\"content\")\n",
    "        list1={'title':[],'href':[],'time':[]}\n",
    "        for a in  links.find_all(\"div\", {\"class\":\"newsItem\"}):   \n",
    "            for p in a.find_all(\"p\", {\"class\":\"join\"}):\n",
    "                for small in p.find_all(\"small\"):\n",
    "                    for btag in small.find_all(\"b\"):\n",
    "\n",
    "                        list1['time'].append(btag.get_text())\n",
    "\n",
    "\n",
    "            for h3 in a.find_all(\"h3\"):\n",
    "                   for atag in h3:\n",
    "\n",
    "                        list1['title'].append(atag.get_text())\n",
    "\n",
    "\n",
    "                        if \"https://\" in atag['href']:\n",
    "\n",
    "                            list1['href'].append(atag['href'])\n",
    "\n",
    "                        else:    \n",
    "\n",
    "                            list1['href'].append(\"https://www.faa.gov\"+atag['href'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        FAA = pd.DataFrame(list1, columns=['time', 'title', 'href'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # NIST\n",
    "\n",
    "        # In[5]:\n",
    "\n",
    "\n",
    "\n",
    "        url=\"https://www.nist.gov/news-events/news\"\n",
    "        request=req.Request(url, headers={\"user-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36\"})\n",
    "        with req.urlopen(request) as response:\n",
    "            data=response.read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "        root=bs4.BeautifulSoup(data, \"html.parser\")\n",
    "        links=root.find('div',class_=\"nist-block nist-block--news\")\n",
    "        list1={'title':[],'href':[],'time':[]}\n",
    "        for a in  links.find_all(\"article\", {\"class\":\"nist-teaser\"}):    \n",
    "                for b in  a.find_all(\"div\", {\"class\":\"nist-teaser__content-wrapper\"}): \n",
    "                    for time in b.find_all(\"time\"):\n",
    "\n",
    "                        list1['time'].append(time.get_text())\n",
    "\n",
    "                    for title in b.find_all(\"span\"):\n",
    "\n",
    "                        list1['title'].append(title.get_text())\n",
    "\n",
    "                    for p in b.find_all(\"a\"):\n",
    "                            if \"https://\" in p['href']:\n",
    "\n",
    "                                list1['href'].append(p['href'])\n",
    "\n",
    "                                print(\"\")\n",
    "                            else:    \n",
    "\n",
    "                                list1['href'].append(\"https://www.nist.gov\"+p['href'])\n",
    "                                print(\"\")\n",
    "\n",
    "\n",
    "        NIST = pd.DataFrame(list1, columns=['time', 'title', 'href'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # 建立各自panda dataframe  加上website 標籤\n",
    "\n",
    "        # In[6]:\n",
    "\n",
    "\n",
    "\n",
    "        NIST['website'] = 'NIST'\n",
    "\n",
    "\n",
    "        FAA['website'] = 'FAA'\n",
    "\n",
    "\n",
    "        NSF['website'] = 'NSF'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # 合成一個大的table 用時間排序\n",
    "\n",
    "        # In[7]:\n",
    "\n",
    "\n",
    "        merged_df = pd.concat([NIST, FAA, NSF])\n",
    "        merged_df = merged_df[['time', 'website', 'title', 'href']]\n",
    "        merged_df['time'] = pd.to_datetime(merged_df['time'])\n",
    "        merged_df = merged_df.reset_index(drop=True)\n",
    "        \n",
    "       \n",
    "          \n",
    "        merged_df=merged_df.sort_values(by=['time'], ascending=False)\n",
    "        merged_df=merged_df.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        # check if url in db\n",
    "       \n",
    "       \n",
    "        DATABASE_URL = os.popen('heroku config:get DATABASE_URL -a django-heroku-craw').read()[:-1]\n",
    "        from sqlalchemy import create_engine\n",
    "        import psycopg2 \n",
    "        import io\n",
    "\n",
    "\n",
    "        merged_df.head(0).to_sql('crawing_record',DATABASE_URL, if_exists='replace',index=False) #truncates the table\n",
    "\n",
    "        conn = psycopg2.connect(DATABASE_URL, sslmode='require')\n",
    "        cur = conn.cursor()\n",
    "        output = io.StringIO()\n",
    "        merged_df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "        output.seek(0)\n",
    "        contents = output.getvalue()\n",
    "        cur.copy_from(output, 'crawing_record', null=\"\") # null values become ''\n",
    "        conn.commit()\n",
    "        \n",
    "        cur.close()\n",
    "        conn.close()\n",
    "       \n",
    "       \n",
    "                    \n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
